{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jellyfish in /home/nfaggian/development/miniconda/envs/py2/lib/python2.7/site-packages (0.6.1)\n",
      "Collecting numpy\n",
      "  Using cached https://files.pythonhosted.org/packages/de/37/fe7db552f4507f379d81dcb78e58e05030a8941757b1f664517d581b5553/numpy-1.15.4-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.15.4\n"
     ]
    }
   ],
   "source": [
    "!pip install jellyfish numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import BigQuerySource\n",
    "\n",
    "from apache_beam.metrics import Metrics\n",
    "from apache_beam.metrics.metric import MetricsFilter\n",
    "from apache_beam.options.pipeline_options import PipelineOptions, GoogleCloudOptions, StandardOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = PipelineOptions()\n",
    "google_cloud_options = options.view_as(GoogleCloudOptions)\n",
    "google_cloud_options.project = 'anz-pso-nfaggian'\n",
    "google_cloud_options.job_name = 'distance_calculation'\n",
    "google_cloud_options.staging_location = 'gs://anz-pso-nfaggian/stage'\n",
    "google_cloud_options.temp_location = 'gs://anz-pso-nfaggian/temp'\n",
    "options.view_as(StandardOptions).runner = 'DirectRunner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH\n",
    "  name_index AS (\n",
    "   -- name: sorted neighbourhood indexing method \n",
    "  SELECT\n",
    "    donor_id,\n",
    "    name,\n",
    "    address,\n",
    "    ARRAY_AGG(STRUCT(donor_id, name, address)) OVER (ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS name_candidates\n",
    "  FROM (\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      dedup.processed_donors\n",
    "    ORDER BY\n",
    "      name) ),\n",
    "  address_index AS (\n",
    "  -- address: sorted neighbourhood indexing method\n",
    "  SELECT\n",
    "    donor_id,\n",
    "    name,\n",
    "    address,\n",
    "    ARRAY_AGG(STRUCT(donor_id, name, address)) OVER (ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS address_candidates\n",
    "  FROM (\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      dedup.processed_donors\n",
    "    ORDER BY\n",
    "      address) )\n",
    "SELECT\n",
    "  name_index.donor_id,\n",
    "  name_index.name,\n",
    "  name_index.name_candidates,\n",
    "  address_index.address,\n",
    "  address_index.address_candidates\n",
    "FROM\n",
    "  address_index\n",
    "JOIN\n",
    "  name_index\n",
    "ON\n",
    "  address_index.donor_id = name_index.donor_id\n",
    "LIMIT 500\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish as jf\n",
    "import numpy as np\n",
    "\n",
    "class indexer(beam.DoFn): \n",
    "    \"\"\"\n",
    "    Forms candidate pairs from a structured query\n",
    "    \"\"\"\n",
    "    def process(self, element):\n",
    "        \"\"\"\n",
    "        Split the candidates\n",
    "        \"\"\"    \n",
    "        candidate_groups = ['address_candidates', 'name_candidates']\n",
    "        for group in candidate_groups:\n",
    "            for candidate in element[group]:\n",
    "                yield {'record_a': {'donor_id': element['donor_id'], \n",
    "                                    'name': unicode(element['name']), \n",
    "                                    'address': unicode(element['address'])},\n",
    "                       'record_b': {'donor_id': candidate['donor_id'], \n",
    "                                    'name': unicode(candidate['name']), \n",
    "                                    'address': unicode(candidate['address'])}}\n",
    "                \n",
    "def comparator(element):\n",
    "    \"\"\"\n",
    "    Extract similarity features\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'donor_id1': element['record_a']['donor_id'],\n",
    "        'donor_id2': element['record_b']['donor_id'],\n",
    "        'jaro_name': jf.jaro_winkler(element['record_a']['name'], element['record_b']['name']),\n",
    "        'damerau_name': jf.damerau_levenshtein_distance(element['record_a']['name'], element['record_b']['name']),\n",
    "        'jaro_address': jf.jaro_winkler(element['record_a']['address'], element['record_b']['address']),\n",
    "        'damerau_address': jf.damerau_levenshtein_distance(element['record_a']['address'], element['record_b']['address'])  \n",
    "        }\n",
    "                \n",
    "def baseline_classifier(element):\n",
    "    \"\"\"\n",
    "    Simple voting classifier.\n",
    "    * assumes an equal weighting for the different types of distance metrics. \n",
    "    \"\"\"\n",
    "    votes = [\n",
    "        element['jaro_name'] > 0.67,\n",
    "        element['jaro_address'] > 0.67,\n",
    "        element['damerau_name'] < 9,\n",
    "        element['damerau_address'] < 9]\n",
    "    return {'donor_id1': element['donor_id1'], \n",
    "            'donor_id2': element['donor_id2'], \n",
    "            'classification': np.mean(votes)}                \n",
    "\n",
    "\n",
    "schema = 'donor_id1:STRING, donor_id2:STRING, classfication:FLOAT'\n",
    "\n",
    "def printfn(x): print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline(options=options) as p:\n",
    "     \n",
    "    _ = (p \n",
    "        | \"query\" >> beam.io.Read(beam.io.BigQuerySource(query=query, \n",
    "                                                         project='anz-pso-nfaggian', \n",
    "                                                         use_standard_sql=True))\n",
    "        | \"record generator\" >> beam.ParDo(indexer())\n",
    "        | \"feature extraction\" >> beam.Map(lambda x: comparator(x)) \n",
    "        | \"duplicate classifier\" >> beam.Map(lambda x: baseline_classifier(x)) \n",
    "        | \"store\" >> beam.io.Write(beam.io.BigQuerySink('dedup.classification', \n",
    "                                                        schema=schema, \n",
    "                                                        create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED, \n",
    "                                                        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE))\n",
    "        )\n",
    "    \n",
    "    result = p.run().wait_until_finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
